
##MCLExtention='I65'#change the MCLExtention if you want to process file created with another inflation value
###if inflation value =2, extention = I20, if inflation value=6 extention=I60 etc...
##print MCLExtention

#FIND AN ALTERNATIVE (OPEN FULL FILE IN ONE GO???)



def MCLRatio(MCLDumpDir, MCLExtention, Db_Id_List_Folder, outfile):
    """This function require python 2.7 and Biopython 1.6 or above
   
    MCLDumpDir is a directory that should contain the dump file generated by MCL
        for the JacKnife analysis
    MCLExtension is a string that match the extention to analyse.
        eg using the nomenclature used in the MCL tutorial file, cluster generated 
        with an inflation value of 6 should follow the pattern dump.NAME.I60
        in that case the extention should be 'I60' and NOT '.I60' 
    Db_Id_List_Folder is a folder that contain the list of protein Id that where kept 
        for each database created for the JackKnife analysis
    Outfile is the name of a file or file + path that will be written at the end"""
    import os
    from Bio import SeqIO
    import time
    AssoDic={} # create a dictionnary in which keys will be 2 protein index associated at least once
    TreatedFile=[] # List of Unique identifier. Might need removal to make the function more universal --==[[]
    MCL_Dir=os.path.join(os.getcwd(), MCLDumpDir) #set the folder containing the MCL dump file as a wd
    ##--For each file, check protein association in the same clusters and count it--#
    for index, file in enumerate(os.listdir(MCL_Dir)):
        t0=time.time() #used to evaluate the time recquired to run the loop on 1 file
        if MCLExtention in file.split('.'):
            FH=open(os.path.join(MCL_Dir, file),'r')
            TreatedFile.append(file.split('_')[3:5]) #unique identifier Might need removal to make the function more universal --==[[]
            for line in FH:
                DoneList=[]
                AssoList=[(element1, element2)
                for element1 in line.strip().split('\t')
                for element2 in line.strip().split('\t')
                if element1 != element2]
                for pair in AssoList:
                    if pair not in DoneList or pair[::-1] not in DoneList:
                        if pair in AssoDic or pair[::-1] in AssoDic:
                            try:
                                AssoDic[pair]=AssoDic.get(pair)+1
                            except:
                                AssoDic[pair[::-1]]=AssoDic.get(pair[::-1])+1
                        else:
                            AssoDic[pair]=1
                    DoneList.append(pair)


        print 'file %s done in %.2f sec'%(file, time.time()-t0) #give the name of the file that have been through the all loop and the time needed to do so
    else:
        print '%s association found over %s files'%(len(AssoDic), index+1) #give the size of the AssoDic

    ##--Create a Dictionnary that contain all the key form AssoDic--#
    PresenceDic={key:0
    for key in AssoDic.iterkeys()}
    #This Dictionary will be use to check how many time two protein associated at least one are present in the same Database
    
    IDFOLDER=os.path.join(os.getcwd(), Db_Id_List_Folder)
    ##--Count how many time associated protein are in the same DB--#
    for DB_Id_List_File in os.listdir(IDFOLDER): 
        if DB_Id_List_File.split('_')[1:3] in TreatedFile: #unique identifier Might need removal to make the function more universal --==[[]
            FH=open(os.path.join(IDFOLDER, DB_Id_List_File), 'r')
            OpenIdList=FH.read().strip()

            IdSet=set((element, element2)
            for element in OpenIdList
            for element2 in OpenIdList
            if element!=element2)
                
            CommonSet=IdSet&set(AssoDic.keys())

            for Pair in CommonSet:
                PresenceDic[Pair]=PresenceDic.get(Pair)+1
        print '%s done in %.2f sec'%(DB_Id_List_File, time.time()-t0)
    else:
        print 'opening output file'
    
    fileout=open(outfile, 'w')
    ##--Calculate Ratio--#
    for Pair in AssoDic:
        PairRatio=(AssoDic.get(Pair))/float(PresenceDic.get(Pair))
        print>>fileout,  "%s,%s,%s,%s,%s"%(
                            Pair[0], Pair[1], AssoDic.get(Pair), PresenceDic.get(Pair), PairRatio)
    else:
        fileout.close()
    
    #dic is useless just write the result in the file
    



MCLRatio('JK_DUMP_updated','I65','LISTIDJK_updated' , 'Test_Ratio_MCL_20140226.csv')
#    RatioDic={Pair:float(AssoDic.get(Pair))/float(PresenceDic.get(Pair))
#        for Pair in AssoDic}
    
    
    

#
###INDEX DICT needed to write table at the end ? ===> no if I do a 5 column table, prot A, prot B , count, presence,ratio
#
#
#
#
#for key in AssoDic: #for each protein association detected in MCL using a given inflation value (6 if extention ==I60)
#    t0=time.time()
#    ProtID_1=ReverseIndexDict.get(key[0]) #use the reverse index dictionnary to get the protein id associated with the index in...
#    ProtID_2=ReverseIndexDict.get(key[1])#... the AssoDic key [0] and [1]
#    AssoDic[key]=(AssoDic.get(key), 0)#transform the value in AssoDic to a tuple in which the second element, here 0 will be use to count how many time prot 1 and 2 are in the same database
#    for file in os.listdir(IDListPath): #for each file
#        OpenFile=open(os.path.join(IDListPath, file), 'r') #read the file
#        OpenFileRead=OpenFile.read().strip() #store the file as a string (it's a small file so should be ok)
#        if ProtID_1 in OpenFileRead and ProtID_2 in OpenFileRead: #correction compare to the previous version
#            AssoDic[key]=(AssoDic.get(key)[0], AssoDic.get(key)[1]+1) #every time the protein id from the AssoKey are found in the same file then add +1 to AssoDic.get(key)[1]
#            OpenFile.close() #close the file because it is not needed anymore
#    print 'key %s,%s done in %.3f sec' %(ProtID_1, ProtID_2, time.time()-t0) #give the time necessary to treat one key from AssoDic
#
##previous version was ## ProtID_1 and ProtID_2 in OpenFile.read().strip():
##but was only checking for the presence of ProtID_2 in the open file
##ProtID_1 was just assumed as true as the value exist
##using ## ProtID_1 in OpenFile.read().strip() and ProtID_2 in OpenFile.read().strip():
##does not work because the first part of the if statment (before "and") read the openfile
##reach the end and does not go back to the start so ProtID_2 cannot be find in the file
##new version is storing the file as a str under the name OpenFileRead
#
#LineDict={} #create a new dictionnary that will be use to write data on an outputfile
#for k in AssoDic: 
#    if k[0] in LineDict:
#        LineDict.get(k[0]).append(k[1])
#    else:
#        LineDict[k[0]]=[k[1]]
##the new data structure is
##key = 1 prot Id, value = list of protein associated with it in all the dump files
#
#
#RatioOutFilePath='RatioFile%s.csv'%MCLExtention #create an output file 
#RatioOutFile=open(RatioOutFilePath,'w')#create the output file in the current directory
##The output file can be big (300 000 mb in the current version)
#
#LineList=[]#List that will be used to print each line in the output file
#for HeaderKey in sorted(ReverseIndexDict):
#    LineList.append(ReverseIndexDict.get(HeaderKey))
##the for loop above define the Header
##DATA Structure in the output file
##'space' protIDx...ProtID1,ProtID0
##ProtID0                ratio
##ProtID1
##....
##ProtIDx
##with x == len(indexDict)-1
##ratio is value between 0 and 1 corresponding to 
##nb of time protein 1 and 0 are in the same cluster / nb time protein 1 and 0 are in the same database
##if protein 1 and 0 are always associated, ratio ==1
##protein 1 and 0 never associated, ratio ==0
#
#
#LineList.append('')#to create an empty column in the heade
#print>>RatioOutFile, ','.join(LineList[::-1]) #print the header in reverse (see data structure above)
#    
#
#for i in xrange(len(indexDict)): #see description under the for loop
#    t0=time.time()
#    LineList=['']*(len(indexDict)) #for each protein reset LineList to an empty list as long as the indexDict
#    if i in LineDict: #if i is an index that can be find in LineDict:
#        for LDelement in LineDict.get(i): #for each protein associated with protein index i
#            LineList[LDelement]=str(float(AssoDic.get((i, LDelement))[0])/float(AssoDic.get((i, LDelement))[1])) #get the association ratio protein i with protein LDelement
#    LineList.append(ReverseIndexDict.get(i)) #add the protein i ID as the last element of the LineList
#    print>>RatioOutFile, ','.join(LineList[::-1]) #reverse the LineList (so prot ID first) and print it to the output file
#    print 'line %s done in %.3f sec'%(i, time.time()-t0) #give the time recquired to deal with one key
#
##using i in xrange(len(indexDict)) instead of key in LineDic is better because
##LineDic does not contain the prot id that do not have any hit after the blast
##therefore LineDic is smaller that indexDict and would skip some protein present in the original fasta file
#
##---------------------------------------------------
##This part read the ratio table, and put all the ratio value in a new table
##this table is then used in R to plot the distribution of the ratio
#
#FP='D:\Cluster_P.infestans_20131017\RatioFileI60.csv'
#FH=open(FP, 'r')
#import csv
#dialect=csv.Sniffer().sniff(FH.read(2048))
#Reader=csv.reader(FH, dialect)
#Dic={}
#
#
#for index, line in enumerate(Reader):
#    if index!=0:
#        for ele in line[1::]:
#            if ele!='':
#                if line[0] in Dic:
#                    Dic.get(line[0]).append(ele)
#                else:
#                    Dic[line[0]]=[ele]
#
##len(Dic)
#
#fileout=open('D:\Cluster_P.infestans_20131017\RatioFileI60_ValueOnly.csv', 'w')
#
#for k in Dic.iterkeys():
#    for element in Dic.get(k):
#        print>>fileout,  float(element)
#    
#
#
#print 'done'




